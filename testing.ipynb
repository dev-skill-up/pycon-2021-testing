{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Unit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teacher: [Moshe Zadka](https://cobordism.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start time: **15:00 US/Eastern**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement of Country\n",
    "\n",
    "Belmont (in San Francisco Bay Area Peninsula)\n",
    "\n",
    "Ancestral homeland of the Ramaytush Ohlone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equipment check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter\n",
    "\n",
    "Run and connect to Jupyter.\n",
    "\n",
    "If you installed it locally,\n",
    "`http://localhost:8888`\n",
    "is the default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should not be any output from this step. If an error occured saying \"module not found\", make sure the virtual environment has `ipytest` installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing and running tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize('value', [1, 2])\n",
    "def test_something(value):\n",
    "    assert value != value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-check\n",
    "\n",
    "Run it yourself.\n",
    "\n",
    "Check to see the same thing happened!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_something():\n",
    "    assert 1 == 1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test is a combination of two things:\n",
    "\n",
    "* Running the \"system under test\"\n",
    "* Checking the results\n",
    "\n",
    "Assertions help check the result is correct.\n",
    "Unless the only goal of the test is to check the SUT\n",
    "ran without errors, you will need to check something.\n",
    "\n",
    "Assertions in `pytest` use the Python `assert` statement.\n",
    "\n",
    "The statement checks that its input is a truthy value,\n",
    "and otherwise raises an `AssertionError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert 1 == 0\n",
    "except AssertionError as exc:\n",
    "    print(repr(exc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert 1 == 0, \"math is still ok\"\n",
    "except AssertionError as exc:\n",
    "    print(repr(exc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert 1 == 1, \"math is weird\"\n",
    "except AssertionError as exc:\n",
    "    print(repr(exc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Pytest handles assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "import pytest\n",
    "\n",
    "def test_math():\n",
    "    assert 1 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When tests are running in `pytest`,\n",
    "it modifies the `assert` statement\n",
    "so that it can give more informative errors.\n",
    "\n",
    "It will give diffs, further details,\n",
    "or explanations as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading assertion failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is the *running output*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will often see this in build log,\n",
    "or on the console,\n",
    "*while* the tests are running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows you the status of each test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "============================= test session starts ==============================\n",
    "platform linux -- Python 3.9.0, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 -- /opt/carme/venvs/testing-in-python/bin/python\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /opt/carme/src/testing-in-python/session-1\n",
    "collecting ... collected 1 item\n",
    "\n",
    "tmpz_pjyxpu.py::test_something FAILED                                    [100%]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is the\n",
    "*failure details section*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will have a subsection for each failing test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows you details about the failure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Code snippet\n",
    "* Values of relevant parts of the assertion\n",
    "* (Sometimes) a diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=================================== FAILURES ===================================\n",
    "________________________________ test_something ________________________________\n",
    "\n",
    "    def test_something():\n",
    ">       assert 1 == 1 + 1\n",
    "E       assert 1 == 2\n",
    "E         +1\n",
    "E         -2\n",
    "\n",
    "<ipython-input-3-8b025c28988b>:2: AssertionError\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part is the failure summary. It shows you how many tests succeeded and failed,\n",
    "and a few details about each success/failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous example was so minimal, it is not obvious how the parts relate.\n",
    "You can learn from a slightly more complicated example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_error():\n",
    "    assert 0 == 1\n",
    "    \n",
    "def test_succeed():\n",
    "    assert 1 == 1\n",
    "    \n",
    "def test_fail():\n",
    "    assert 1/0 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few things to notice:\n",
    "\n",
    "* A succeeding test is not mentioned by name in the summary, but it is counted\n",
    "* A failure that is *not* caused by an assertion is a lot less obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example: you have a function that implements addition.\n",
    "Unfortunately, it has a bug -- it returns the expected result with a small difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def add(a, b):\n",
    "    result = 0.1 # This is a mistake -- should be 0\n",
    "    result += a\n",
    "    result += b\n",
    "    return result\n",
    "\n",
    "def test_add():\n",
    "    assert add(3, 4) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example contains few lines of code, but still has some subtleties to unpack:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The test was comparing `add()` to the *expected result* because, presumably, this is what the function was documented to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The test did not care about the *implementation* of `add()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to implement `add()` (incorrectly) is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def add(a, b):\n",
    "    return (\n",
    "        a +\n",
    "        b + \n",
    "        0.1 # This is a mistake -- should be 0\n",
    "    )\n",
    "\n",
    "def test_add():\n",
    "    assert add(3, 4) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test failed in precisely the same way. The test only checks `add()` against the documented guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because in this case, the documented guarantees are strict and possible to plan for,\n",
    "this test works well with an equality assertion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With lists\n",
    "there are three potential things that can happen.\n",
    "\n",
    "1. The list on the right might be a proper prefix of the list on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_missing():\n",
    "    assert [1] == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The list on the left might be a proper prefix of the list on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_extra():\n",
    "    assert [1] == [1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. At least in one index, the element at that index in both lists is different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_different():\n",
    "    assert [1, 2, 3] == [1, 4, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These failures are *different*.\n",
    "Learning how to read the failures,\n",
    "and understanding what's wrong is important.\n",
    "This is not just important when troubleshooting a failing test.\n",
    "It is also important when writing tests:\n",
    "remember, every assertion has to pay rent by being simulated\n",
    "with a bug in the system under test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to compare strings:\n",
    "from expected output to running external commands,\n",
    "many things are strings that have strict equality guarantees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_string():\n",
    "    assert \"hello\\nworld\" == \"goodbye\\nworld\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the length of the string, sometimes an inside-the-line diff will be triggered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_string():\n",
    "    assert \"saying \" * 10 + \"hello world\" + \" said\" * 10 == \"saying \" * 10 + \"goodbye world\" + \" said\" * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytest` will try to give useful diffs with most containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_set():\n",
    "    assert set([1,2]) == set([1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sets, it will check for spurious elements on both sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip -- Inserting Exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting exceptions into tests is a surprisingly good way to debug test failures.\n",
    "\n",
    "* You can make sure the test fails: test fail with exceptions!\n",
    "* The exception -> test failure output is the most reliable output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def subtle_manipulation(things):\n",
    "    trim = 1 # It should be 2\n",
    "    return things[trim:-trim]\n",
    "\n",
    "def test_subtle_manipulation():\n",
    "    assert subtle_manipulation(\"--HELLO--\") == \"HELLO\"\n",
    "\n",
    "def erroring_subtle_manipulation(things):\n",
    "    trim = 1\n",
    "    ret_value = things[trim:-trim]\n",
    "    raise ValueError(things, ret_value, trim)\n",
    "    return ret\n",
    "\n",
    "def test_subtle_manipulation_2():\n",
    "    assert erroring_subtle_manipulation(\"--HELLO--\") == \"HELLO\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually inequality is asserted as a \"helper\" assertion.\n",
    "For example, if a function is defined to produce a \"different\" example for something,\n",
    "it might be reasonable to also verify that these examples are all indeed different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytest will still print the values,\n",
    "but in this case, there is no diff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_not_equal():\n",
    "    x = 1\n",
    "    y = x / 1\n",
    "    assert x != y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inequality is not just for numbers:\n",
    "there are other objects that might need to be compared for inequality.\n",
    "Again, notice what pytest does and does not output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_not_equal_lists():\n",
    "    x = [1, 2, 3]\n",
    "    assert x != x[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stronger assertion is *order*.\n",
    "Both the `<` and `<=` operators, as well as their inverses, can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_greater():\n",
    "    x = 1\n",
    "    assert x < x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be mindful of which ordering operator you want:\n",
    "always think about the semantics and whether `<` or `<=` is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_greater_or_equal():\n",
    "    x = 1\n",
    "    assert x + 1 <= x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets can also be compared.\n",
    "Note that there is no diff.\n",
    "Compare two tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "SMALLER = {1, 2, 3}\n",
    "BIGGER = {1, 2}\n",
    "\n",
    "def test_set_comparison():\n",
    "    assert SMALLER <= BIGGER\n",
    "    \n",
    "def test_set_comparison_with_equality():\n",
    "    assert SMALLER & BIGGER == SMALLER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `in` and `not in` operators are sometimes useful to assert about items and containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_in():\n",
    "    assert 5 in range(3)\n",
    "    \n",
    "def test_not_in():\n",
    "    assert 1 not in set([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, you want to verify the actual identity of objects.\n",
    "Note that the behavior of `is` on built-in constants is awkwardly defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_identical():\n",
    "    assert [1, 2, 3] is [1, 2, 3]\n",
    "    \n",
    "def test_not_identical():\n",
    "    x = \"hello\"\n",
    "    assert x is not x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All comparison operators in Python (`==` and the others)\n",
    "*chain*.\n",
    "Pytest special-cases comparison chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def test_equality_chain():\n",
    "    x = [1, 2, 3]\n",
    "    assert [1, 2, 3] == x == [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there will be a direct boolean you want to assert.\n",
    "In that case, it is useful to put the place this boolean came from\n",
    "in the test assertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def always_false(something):\n",
    "    return False\n",
    "\n",
    "def test_false():\n",
    "    x = [1, 2, 3]\n",
    "    x.append(4)\n",
    "    x.append(4)\n",
    "    assert always_false(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Video will pause for 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def safe_remove(a, b):\n",
    "    pass # fix this line\n",
    "\n",
    "def test_safe_remove_no():\n",
    "    things = {1: \"yes\", 2: \"no\"}\n",
    "    safe_remove(things, 3)\n",
    "    assert 1 in things\n",
    "\n",
    "def test_safe_remove_yes():\n",
    "    things = {1: \"yes\", 2: \"no\"}\n",
    "    safe_remove(things, 2)\n",
    "    assert 2 not in things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def get_min_max(a, b):\n",
    "    return a, b # fix this line\n",
    "\n",
    "def test_min_max_high():\n",
    "    a, b = get_min_max(2, 1)\n",
    "    assert set([a, b]) == set([1, 2])\n",
    "    assert a < b\n",
    "\n",
    "def test_min_max_low():\n",
    "    a, b = get_min_max(1, 2)\n",
    "    assert set([a, b]) == set([1, 2])\n",
    "    assert a < b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def safe_remove(a, b):\n",
    "    a.pop(b, None)\n",
    "\n",
    "def test_safe_remove_no():\n",
    "    things = {1: \"yes\", 2: \"no\"}\n",
    "    safe_remove(things, 3)\n",
    "    assert 1 in things\n",
    "\n",
    "def test_safe_remove_yes():\n",
    "    things = {1: \"yes\", 2: \"no\"}\n",
    "    safe_remove(things, 2)\n",
    "    assert 2 not in things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "def get_min_max(a, b):\n",
    "    return min([a, b]), max([a, b])\n",
    "\n",
    "def test_min_max_high():\n",
    "    a, b = get_min_max(2, 1)\n",
    "    assert set([a, b]) == set([1, 2])\n",
    "    assert a < b\n",
    "\n",
    "def test_min_max_low():\n",
    "    a, b = get_min_max(1, 2)\n",
    "    assert set([a, b]) == set([1, 2])\n",
    "    assert a < b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "* Tests: run + verify\n",
    "* Assertions verify\n",
    "* Pytest rewrites `assert`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break\n",
    "\n",
    "Video will pause for 10m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are mocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mocks are found in the module `unittest.mock` in the standard library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common class is `MagicMock()`, and will be the main one this class covers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see mocks in action, you can intentionally fail some tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a function that raises an exception is a good way to see how mocks work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def raise_value(x):\n",
    "    raise ValueError(x)\n",
    "\n",
    "def test_value():\n",
    "    raise_value(mock.MagicMock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default mock properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mocks have every attribute. It is also a mock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def raise_some_name(x):\n",
    "    raise ValueError(x.some_name)\n",
    "\n",
    "def test_name():\n",
    "    raise_some_name(mock.MagicMock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mock's attribtues are *consistent*.\n",
    "They stay the same, so retrieving the same attribute again gives identical objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_consistent():\n",
    "    obj = mock.MagicMock()\n",
    "    assert obj.some_name is not obj.some_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling mocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mocks can be called. They return a mock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def raise_call(x):\n",
    "    raise ValueError(x())\n",
    "\n",
    "def test_examine():\n",
    "    raise_call(mock.MagicMock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling a mock again. it will again return the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_consistent_call():\n",
    "    obj = mock.MagicMock()\n",
    "    assert obj() is not obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because an attribute returns a mock, and mocks can be called,\n",
    "mocks also have all the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def raise_deep(x):\n",
    "    val = x.some_method()\n",
    "    raise ValueError(val.some_attribute)\n",
    "    \n",
    "def test_deep():\n",
    "    raise_deep(mock.MagicMock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock magic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Magic` in `MagicMock` is because it also has the so-called \"magic methods\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are the methods that allow objects to overload operations like addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means mocks can also be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def raise_add_1(x):\n",
    "    val = x + 1\n",
    "    raise ValueError(val)\n",
    "    \n",
    "def test_add_1():\n",
    "    raise_add_1(mock.MagicMock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because calling methods on a mock returns the same value, it does not matter what we add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "    \n",
    "def test_add_different():\n",
    "    x = mock.MagicMock()\n",
    "    assert x + 1 != x + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over values is possible, but mocks don't yield any elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def iterate_over(x):\n",
    "    for el in x:\n",
    "        raise ValueError(el)\n",
    "    raise ValueError(\"no elements\", x)\n",
    "    \n",
    "def test_iterate():\n",
    "    iterate_over(mock.MagicMock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless whether you use the `[]` operator with indices, slices, or step-slices, mocks will return the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def raise_index(x):\n",
    "    raise ValueError(x[5])\n",
    "    \n",
    "def raise_slice(x):\n",
    "    raise ValueError(x[5:7])\n",
    "\n",
    "def raise_step_slice(x):\n",
    "    raise ValueError(x[::-1])\n",
    "    \n",
    "def test_index():\n",
    "    raise_index(mock.MagicMock())\n",
    "\n",
    "def test_slice():\n",
    "    raise_slice(mock.MagicMock())\n",
    "    \n",
    "def test_step_slice():\n",
    "    raise_step_slice(mock.MagicMock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mocks can be *named*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naming mocks is a good practice. This makes many errors easier to disagnose from the exception or assertion message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def copy_stuff(source, target):\n",
    "    write_to(target, source, 10)\n",
    "    \n",
    "def write_to(source, target, length):\n",
    "    stuff = source.read()\n",
    "    target.write(stuff)\n",
    "    raise ValueError(source, target, stuff)\n",
    "\n",
    "def test_opaque():\n",
    "    source = mock.MagicMock()\n",
    "    target = mock.MagicMock()\n",
    "    copy_stuff(source, target)\n",
    "    \n",
    "def test_clear():\n",
    "    source = mock.MagicMock(name=\"source\")\n",
    "    target = mock.MagicMock(name=\"target\")\n",
    "    copy_stuff(source, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare \n",
    "\n",
    "```\n",
    "ValueError: (<MagicMock id='140019688468192'>, <MagicMock id='140019688435776'>, <MagicMock name='mock.read()' id='140019688426272'>)\n",
    "```\n",
    "\n",
    "with \n",
    "\n",
    "```\n",
    "ValueError: (<MagicMock name='target' id='140019688082976'>, <MagicMock name='source' id='140019895734528'>, <MagicMock name='target.read()' id='140019895731680'>)\n",
    "```\n",
    "\n",
    "With `target.read()`, the bug is much easier to spot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting properties and deep properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_attribute():\n",
    "    x = mock.MagicMock(name=\"thing\")\n",
    "    x.some_attribute = 5\n",
    "    assert x.some_attribute != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the attribute in the constructor.\n",
    "This is usually better, because there is no step\n",
    "where the mock object is not correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_attribute_constructor():\n",
    "    x = mock.MagicMock(name=\"thing\", some_attribute=5)\n",
    "    assert x.some_attribute != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because by default every attribute on a mock is a mock itself,\n",
    "you can set \"deep attributes\" that violate the \"law\" of Demeter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, it's fine -- although some argue that the test\n",
    "is not a \"unit test\" if this is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_deep_attribute():\n",
    "    x = mock.MagicMock(name=\"thing\")\n",
    "    x.some_attribute.value = 5\n",
    "    assert x.some_attribute.value != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set several attributes,\n",
    "deep or otherwise,\n",
    "on a mock at the same time using\n",
    "`configure_mock`.\n",
    "This is no different than using the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_config_mock():\n",
    "    x = mock.MagicMock(name=\"thing\")\n",
    "    x.configure_mock(**{\n",
    "        \"some_attribute.value\": 5,\n",
    "        \"gauge\": 7,\n",
    "    })\n",
    "    assert x.some_attribute.value != 5 or x.gauge != 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Video will pause for 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def add_1(x):\n",
    "    return x.value + 1\n",
    "\n",
    "def test_deep_attribute():\n",
    "    x = mock.MagicMock(name=\"thing\")\n",
    "    pass # Change only this line\n",
    "    assert add_1(x.some_attribute) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "def add_1(x):\n",
    "    return x.value + 1\n",
    "\n",
    "   \n",
    "def test_config_mock():\n",
    "    x = mock.MagicMock(name=\"thing\")\n",
    "    x.configure_mock(**{\n",
    "        # Change only this line\n",
    "        \"gauge\": 7,\n",
    "    })\n",
    "    assert add_1(x.some_attribute) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def add_1(x):\n",
    "    return x.value + 1\n",
    "\n",
    "def test_deep_attribute():\n",
    "    x = mock.MagicMock(name=\"thing\")\n",
    "    x.some_attribute.value = 1 # pass # Change only this line\n",
    "    assert add_1(x.some_attribute) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "def add_1(x):\n",
    "    return x.value + 1\n",
    "\n",
    "   \n",
    "def test_config_mock():\n",
    "    x = mock.MagicMock(name=\"thing\")\n",
    "    x.configure_mock(**{\n",
    "        \"some_attribute.value\": 1, # Change only this line\n",
    "        \"gauge\": 7,\n",
    "    })\n",
    "    assert add_1(x.some_attribute) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "* Name mocks\n",
    "* Set properties and \"deep\" properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break\n",
    "\n",
    "Video will pause for 10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Mocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's duck-typing means that often what we want to do with mock objects is *call them* (or *call methods on them*) and get specific return values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mock object returns whatever value is in its `return_value` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like any attribute, a mock object will have that attribute,\n",
    "and it will be a mock by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_use_return_value():\n",
    "    obj = mock.MagicMock(name=\"obj\")\n",
    "    obj.return_value.some_attribute = 5\n",
    "    assert obj().some_attribute != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in other cases of \"deep attributes\", you can set it in the constructor with the right \"keyword arguments\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_use_return_value_constructor():\n",
    "    obj = mock.MagicMock(name=\"obj\", **{\"return_value.some_attribute\": 5})\n",
    "    assert obj().some_attribute != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set the `return_value` property itself, which will return a regular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_set_return_value():\n",
    "    obj = mock.MagicMock(name=\"obj\")\n",
    "    obj.return_value = 5\n",
    "    assert obj() != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set it using the constructor too. Here, a regular keyword argument will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_set_return_value_constructor():\n",
    "    obj = mock.MagicMock(name=\"obj\", return_value=5)\n",
    "    assert obj() != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common occurence is wanting to set the return value of a *method*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_set_rmethod_return_value():\n",
    "    obj = mock.MagicMock(name=\"obj\")\n",
    "    obj.method.return_value = 5\n",
    "    assert obj.method() != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the return value of a method is a \"deep attribute\", so you will need to use the special syntax\n",
    "to pass it in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_set_rmethod_return_value_constructor():\n",
    "    obj = mock.MagicMock(name=\"obj\", **{\"method.return_value\": 5})\n",
    "    assert obj.method() != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all of these ideas together, in order to set an *attribute* on the return value of a *method*,\n",
    "you will have to use the special syntax, and have *two* dots in the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean] -vv\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_set_rmethod_deep_return_value_constructor():\n",
    "    obj = mock.MagicMock(name=\"obj\", **{\"method.return_value.some_attribute\": 5})\n",
    "    assert obj.method().some_attribute != 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock side effect -- iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One of the things that can be assigned to `side_effect` is\n",
    "an *iterable*, such as a sequence or a generator.\n",
    "\n",
    "This is a powerful feature -- it allows controlling each call's return value,\n",
    "with little code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def test_values():\n",
    "    different_things = mock.MagicMock()\n",
    "    different_things.side_effect = [1, 2, 3]\n",
    "    assert different_things() == 1\n",
    "    assert different_things() == 2\n",
    "    assert different_things() == 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more realistic example is when simulating file input.\n",
    "In this case, we want to be able to control what `readline` returns\n",
    "each time to pretend it is file input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "from unittest import mock\n",
    "\n",
    "def parse_three_lines(fpin):\n",
    "    line = fpin.readline()\n",
    "    name, value = line.split()\n",
    "    modifier = fpin.readline().strip()\n",
    "    extra = fpin.readline().strip()\n",
    "    return {name: f\"{value}/{modifier}+{extra}\"}\n",
    "\n",
    "from io import TextIOBase\n",
    "    \n",
    "def test_parser():\n",
    "    filelike = mock.MagicMock(spec=TextIOBase)\n",
    "    filelike.readline.side_effect = [\n",
    "        \"thing important\\n\",\n",
    "        \"a-little\\n\",\n",
    "        \"to-some-people\\n\"\n",
    "    ]\n",
    "    value = parse_three_lines(filelike)\n",
    "    assert value == dict(thing=\"important/a-little+to-most-people\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock side effect -- function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code needs to have the mock objects do some non-trivial computation.\n",
    "For example, when testing code for a network client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to test such code without performing any computation is difficult. The tests tend to be too *insensitive* or too *flakey*. An insensitive test is one that does not fail in the presence of bugs. A flakey test is one that sometimes fails, even when the code is  correct. Here, our code is incorrect. The insensitive test does not catch it, while the flakey test would fail even if it was fixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "import socket\n",
    "import random\n",
    "\n",
    "def yolo_reader(sock):\n",
    "    sock.settimeout(5)\n",
    "    sock.connect((\"some.host\", 8451))\n",
    "    fpin = sock.makefile()\n",
    "    order = [0, 1]\n",
    "    random.shuffle(order)\n",
    "    while order:\n",
    "        if order.pop() == 0:\n",
    "            sock.sendall(b\"GET KEY\\n\")\n",
    "            key = fpin.readline().strip()\n",
    "        else:\n",
    "            sock.sendall(b\"GET VALUE\\n\")\n",
    "            value = fpin.readline().strip()\n",
    "    return {value: key} ## Woops bug, should be {key: value}\n",
    "    \n",
    "from io import TextIOBase\n",
    "from unittest import mock\n",
    "import pytest\n",
    "\n",
    "def test_insensitive_test():\n",
    "    sock = mock.MagicMock(spec=socket.socket)\n",
    "    sock.makefile.return_value.readline.return_value = \"interesting\\n\"\n",
    "    assert yolo_reader(sock) == {\"interesting\": \"interesting\"}\n",
    "    \n",
    "@pytest.mark.parametrize(\"does_nothing\", [1, 2, 3, 4, 5])\n",
    "def test_flakey_test(does_nothing):\n",
    "    sock = mock.MagicMock(spec=socket.socket)\n",
    "    sock.makefile.return_value.readline.side_effect = [\"key\\n\", \"value\\n\"]\n",
    "    assert yolo_reader(sock) == {\"key\": \"value\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final option of getting results from a mock object is to assign a *callable object* to `side_effect`. This calls `side_effect` to simply call it. Why not just assign a callable object directly to the attribute? Have patience, we'll get to that in the next part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, our callable object (just a function) will assign a `return_value` to the attribute of another object. This is not that uncommon. We are simulating the environment, and in a real environment, poking one thing often has an effect on other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "import socket\n",
    "import random\n",
    "\n",
    "def yolo_reader(sock):\n",
    "    sock.settimeout(5)\n",
    "    sock.connect((\"some.host\", 8451))\n",
    "    fpin = sock.makefile()\n",
    "    order = [0, 1]\n",
    "    random.shuffle(order)\n",
    "    while order:\n",
    "        if order.pop() == 0:\n",
    "            sock.sendall(b\"GET KEY\\n\")\n",
    "            key = fpin.readline().strip()\n",
    "        else:\n",
    "            sock.sendall(b\"GET VALUE\\n\")\n",
    "            value = fpin.readline().strip()\n",
    "    return {value: key} ## Woops bug, should be {key: value}\n",
    "    \n",
    "from io import TextIOBase\n",
    "from unittest import mock\n",
    "\n",
    "def test_yolo_well():\n",
    "    sock = mock.MagicMock(spec=socket.socket)\n",
    "    def sendall(data):\n",
    "        cmd, name = data.decode(\"ascii\").split()\n",
    "        if name == \"KEY\":\n",
    "            sock.makefile.return_value.readline.return_value = \"key\\n\"\n",
    "        elif name == \"VALUE\":\n",
    "            sock.makefile.return_value.readline.return_value = \"value\\n\"\n",
    "        else:\n",
    "            raise ValueError(\"got bad command\", name)\n",
    "    sock.sendall.side_effect = sendall\n",
    "    assert yolo_reader(sock) == {\"key\": \"value\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock call args and call args list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call arguments\n",
    "\n",
    "In the following example, we want to make sure the code calls the method with the *correct* arguments.\n",
    "When automating data center manipulations, it is important to get things right.\n",
    "As they say, \"To err is human, but to destroy an entire data center requires a robot with a bug.\"\n",
    "\n",
    "We want to make sure our Paramiko-based automation will correctly get the sizes of files, even when the file names have spaces in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def get_remote_file_size(client, fname):\n",
    "    client.connect('ssh.example.com')\n",
    "    stdin, stdout, stderr = client.exec_command(f\"ls -l {fname}\")\n",
    "    stdin.close()\n",
    "    results = stdout.read()\n",
    "    errors = stderr.read()\n",
    "    stdout.close()\n",
    "    stderr.close()\n",
    "    if errors != '':\n",
    "        raise ValueError(\"problem with command\", errors)\n",
    "    return int(results.split()[4])\n",
    "\n",
    "import pytest\n",
    "from unittest import mock\n",
    "import shlex\n",
    "\n",
    "@pytest.mark.parametrize(\"fname\", [\"readme.txt\", \"a file\"])\n",
    "def test_file_size(fname):\n",
    "    client = mock.MagicMock()\n",
    "    client.exec_command.return_value = [mock.MagicMock(name=str(i)) for i in range(3)]\n",
    "    client.exec_command.return_value[1].read.return_value = f\"\"\"\\\n",
    "    -rw-rw-r--  1 user user    123 Jul 18 20:25 {fname}\n",
    "    \"\"\"\n",
    "    client.exec_command.return_value[2].read.return_value = \"\"\n",
    "    result = get_remote_file_size(client, fname)\n",
    "    assert result == 123\n",
    "    [args], kwargs = client.exec_command.call_args\n",
    "    assert shlex.split(args) == [\"ls\", \"-l\", fname]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of call args\n",
    "\n",
    "Sometimes, this is not enough. Some code calls functions repeatedly, and we need to test that *all* calls are correct.\n",
    "The most sophisticated X-Ray we have is `.call_args_list` which gives the entire history of what happened to the callable.\n",
    "\n",
    "For this example, we will pretend that the (*real*) remote calculator API only allows multiplying two numbers. In order to *cube* the number, calculate `x**3`, we need two calls to the service. For superstitious reasons, we want to always put the bigger number first: maybe someone told us that it is faster this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "import httpx\n",
    "from unittest import mock\n",
    "\n",
    "def calculate_cube(client, base):\n",
    "    square = int(client.get(f\"https://api.mathjs.org/v4/?expr={base}*{base}\").text) # x*x\n",
    "    return int(client.get(f\"https://api.mathjs.org/v4/?expr={base}*{square}\").text) # x*x*x\n",
    "\n",
    "def test_calculate_cube():\n",
    "    client = mock.MagicMock(spec=httpx.Client)\n",
    "    client.get.side_effect = [mock.MagicMock(text=str(x)) for x in [25, 125]]\n",
    "    assert calculate_cube(client, 5) == 125\n",
    "    assert client.get.call_count == 2\n",
    "    squaring, cubing = client.get.call_args_list\n",
    "    args, kwargs = squaring\n",
    "    assert kwargs == {}\n",
    "    assert args == tuple([\"https://api.mathjs.org/v4/?expr=5*5\"])\n",
    "    args, kwargs = cubing\n",
    "    assert kwargs == {}\n",
    "    ## Make sure bigger number comes first!\n",
    "    assert args == tuple([\"https://api.mathjs.org/v4/?expr=25*5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Video will pause for 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "import httpx\n",
    "from unittest import mock\n",
    "import pytest\n",
    "import random\n",
    "\n",
    "def calculate_fifth_power(client, base):\n",
    "    square = int(client.get(f\"https://api.mathjs.org/v4/?expr={base}*{base}\").text)\n",
    "    hypercube = int(client.get(f\"https://api.mathjs.org/v4/?expr={square}*{square}\").text)\n",
    "    # random order\n",
    "    args = [hypercube, base]\n",
    "    random.shuffle(args)\n",
    "    result = int(client.get(f\"https://api.mathjs.org/v4/?expr={args[0]}*{args[1]}\").text)\n",
    "    return result\n",
    "\n",
    "@pytest.mark.parametrize(\"does_nothing\", [1, 2, 3, 4, 5])\n",
    "def test_calculate_cube(does_nothing):\n",
    "    client = mock.MagicMock(spec=httpx.Client)\n",
    "    client.get.side_effect = [mock.MagicMock(text=str(x)) for x in [25, 625, 3125]]\n",
    "    assert calculate_fifth_power(client, 5) == 3125\n",
    "    assert client.get.call_count == 3\n",
    "    squaring, hypercubing, final = client.get.call_args_list\n",
    "    args, kwargs = squaring\n",
    "    assert kwargs == {}\n",
    "    assert args == tuple([\"https://api.mathjs.org/v4/?expr=5*5\"])\n",
    "    args, kwargs = hypercubing\n",
    "    assert kwargs == {}\n",
    "    args, kwargs = final\n",
    "    assert kwargs == {}\n",
    "    [url] = args\n",
    "    constant, expr = url.split(\"=\", 1)\n",
    "    assert constant == \"https://api.mathjs.org/v4/?expr\"\n",
    "    assert expr == \"625*5\" # Change only this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "import httpx\n",
    "from unittest import mock\n",
    "import pytest\n",
    "import random\n",
    "\n",
    "def calculate_fifth_power(client, base):\n",
    "    square = int(client.get(f\"https://api.mathjs.org/v4/?expr={base}*{base}\").text)\n",
    "    hypercube = int(client.get(f\"https://api.mathjs.org/v4/?expr={square}*{square}\").text)\n",
    "    # random order\n",
    "    args = [hypercube, base]\n",
    "    random.shuffle(args)\n",
    "    result = int(client.get(f\"https://api.mathjs.org/v4/?expr={args[0]}*{args[1]}\").text)\n",
    "    return result\n",
    "\n",
    "@pytest.mark.parametrize(\"does_nothing\", [1, 2, 3, 4, 5])\n",
    "def test_calculate_cube(does_nothing):\n",
    "    client = mock.MagicMock(spec=httpx.Client)\n",
    "    client.get.side_effect = [mock.MagicMock(text=str(x)) for x in [25, 625, 3125]]\n",
    "    assert calculate_fifth_power(client, 5) == 3125\n",
    "    assert client.get.call_count == 3\n",
    "    squaring, hypercubing, final = client.get.call_args_list\n",
    "    args, kwargs = squaring\n",
    "    assert kwargs == {}\n",
    "    assert args == tuple([\"https://api.mathjs.org/v4/?expr=5*5\"])\n",
    "    args, kwargs = hypercubing\n",
    "    assert kwargs == {}\n",
    "    args, kwargs = final\n",
    "    assert kwargs == {}\n",
    "    [url] = args\n",
    "    constant, expr = url.split(\"=\", 1)\n",
    "    assert constant == \"https://api.mathjs.org/v4/?expr\"\n",
    "    assert set(expr.split(\"*\")) == {\"625\", \"5\"} # Change only this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts and Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assertions let you verify conditions\n",
    "* Mocks let you avoid interacting with \"real life\"\n",
    "* You can set mock attributes, return values, or even behavior\n",
    "* Mocks record arguments they were called with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testable code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This shows how to test -- but writing testable code is important!\n",
    "* The power of mocks shines when passing arguments to functions or initializers -- do it more.\n",
    "* Patching is a tool of last resort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "testing-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
